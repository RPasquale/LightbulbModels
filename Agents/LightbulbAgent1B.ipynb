{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, image_channels=3, h_dim=1024, z_dim=32):\n",
    "        super(VAE, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(image_channels, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 256, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.fc1 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc2 = nn.Linear(h_dim, z_dim)\n",
    "        self.fc3 = nn.Linear(z_dim, h_dim)\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(64, 32, kernel_size=4, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.ConvTranspose2d(32, image_channels, kernel_size=4, stride=2, padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, log_var):\n",
    "        std = torch.exp(0.5 * log_var)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x):\n",
    "        h = self.encoder(x).view(x.size(0), -1)\n",
    "        mu, log_var = self.fc1(h), self.fc2(h)\n",
    "        z = self.reparameterize(mu, log_var)\n",
    "        z = self.fc3(z).view(x.size(0), 256, 1, 1)\n",
    "        return self.decoder(z), mu, log_var\n",
    "\n",
    "\n",
    "class MDNRNN(nn.Module):\n",
    "    def __init__(self, z_dim, a_dim, h_dim, n_gaussians=5):\n",
    "        super(MDNRNN, self).__init__()\n",
    "        self.rnn = nn.LSTM(z_dim + a_dim, h_dim, batch_first=True)\n",
    "        self.fc = nn.Linear(h_dim, n_gaussians * z_dim * 3)\n",
    "\n",
    "    def forward(self, z, a, h):\n",
    "        x = torch.cat([z, a], dim=-1).unsqueeze(1)\n",
    "        h, _ = self.rnn(x, h)\n",
    "        h = h.squeeze(1)\n",
    "        y = self.fc(h)\n",
    "        return y, h\n",
    "\n",
    "    def init_hidden(self, batch_size, h_dim):\n",
    "        return (torch.zeros(1, batch_size, h_dim),\n",
    "                torch.zeros(1, batch_size, h_dim))\n",
    "\n",
    "\n",
    "class Controller(nn.Module):\n",
    "    def __init__(self, z_dim, h_dim, a_dim):\n",
    "        super(Controller, self).__init__()\n",
    "        self.fc1 = nn.Linear(z_dim + h_dim, a_dim)\n",
    "\n",
    "    def forward(self, z, h):\n",
    "        x = torch.cat([z, h], dim=-1)\n",
    "        return self.fc1(x)\n",
    "\n",
    "\n",
    "class GATOAgent(nn.Module):\n",
    "    def __init__(self, image_channels=3, z_dim=32, a_dim=3, h_dim=256, n_gaussians=5):\n",
    "        super(GATOAgent, self).__init__()\n",
    "        self.vae = VAE(image_channels, h_dim, z_dim)\n",
    "        self.mdnrnn = MDNRNN(z_dim, a_dim, h_dim, n_gaussians)\n",
    "        self.controller = Controller(z_dim, h_dim, a_dim)\n",
    "\n",
    "    def forward(self, image, action, h):\n",
    "        z, mu, log_var = self.vae(image)\n",
    "        mdn_output, h = self.mdnrnn(z, action, h)\n",
    "        action = self.controller(z, h)\n",
    "        return action, h, mu, log_var, mdn_output\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        return self.mdnrnn.init_hidden(batch_size)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
